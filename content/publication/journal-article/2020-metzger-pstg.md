---
abstract: 'Experimentalists studying multisensory integration compare neural responses to multisensory stimuli with responses to the component modalities presented in isolation. This procedure is problematic for multisensory speech perception since audiovisual speech and auditory-only speech are easily intelligible but visual-only speech is not. To overcome this confound, we developed intracranial encephalography (iEEG) deconvolution. Individual stimuli always contained both auditory and visual speech, but jittering the onset asynchrony between modalities allowed for the time course of the unisensory responses and the interaction between them to be independently estimated. We applied this procedure to electrodes implanted in human epilepsy patients (both male and female) over the posterior superior temporal gyrus (pSTG), a brain area known to be important for speech perception. iEEG deconvolution revealed sustained positive responses to visual-only speech and larger, phasic responses to auditory-only speech. Confirming results from scalp EEG, responses to audiovisual speech were weaker than responses to auditory-only speech, demonstrating a subadditive multisensory neural computation. Leveraging the spatial resolution of iEEG, we extended these results to show that subadditivity is most pronounced in more posterior aspects of the pSTG. Across electrodes, subadditivity correlated with visual responsiveness, supporting a model in which visual speech enhances the efficiency of auditory speech processing in pSTG. The ability to separate neural processes may make iEEG deconvolution useful for studying a variety of complex cognitive and perceptual tasks.'
authors:
- Brian A. Metzger, John F. Magnotti, Zhengjia Wang, Elizabeth Nesbitt, Patrick J. Karas, Daniel Yoshor and Michael S. Beauchamp
date: "2020-09-01T00:00:00Z"
doi: "10.1523/JNEUROSCI.0279-20.2020"
url_preprint: "https://www.biorxiv.org/content/10.1101/2020.04.16.045716v1"
featured: false
links: null
projects: null
publication: "Journal of Neuroscience"
publication_short: ""
publication_types:
- "2"
publishDate: "2020-09-01T00:00:00Z"
summary: Visual speech evokes a positive response in the human posterior superior temporal gyrus, enhancing the efficiency of auditory speech processing.
tags:
- "iEEG"
- "RAVE"
- "multisensory"
- "speech perception"
- "superior temporal gyrus"
- "audiovisual"
title: 'Responses to Visual Speech in Human Posterior Superior Temporal Gyrus Examined with iEEG Deconvolution'
---

